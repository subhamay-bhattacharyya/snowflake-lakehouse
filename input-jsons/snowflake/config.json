{
  "warehouses": {
    "load_wh": {
      "name": "LOAD_WH",
      "comment": "This warehouse will be used for loading all the JSON files",
      "warehouse_size": "X-SMALL",
      "auto_resume": true,
      "auto_suspend": 60,
      "enable_query_acceleration": false,
      "warehouse_type": "STANDARD",
      "min_cluster_count": 1,
      "max_cluster_count": 1,
      "scaling_policy": "STANDARD",
      "initially_suspended": true
    },
    "transform_wh": {
      "name": "TRANSFORM_WH",
      "comment": "This warehouse will be used for transform activities",
      "warehouse_size": "X-SMALL",
      "auto_resume": true,
      "auto_suspend": 60,
      "enable_query_acceleration": false,
      "warehouse_type": "STANDARD",
      "min_cluster_count": 1,
      "max_cluster_count": 1,
      "scaling_policy": "STANDARD",
      "initially_suspended": true
    },
    "streamlit_wh": {
      "name": "STREAMLIT_WH",
      "comment": "This warehouse will be used for running Streamlit queries",
      "warehouse_size": "X-SMALL",
      "auto_resume": true,
      "auto_suspend": 60,
      "enable_query_acceleration": false,
      "warehouse_type": "STANDARD",
      "min_cluster_count": 1,
      "max_cluster_count": 1,
      "scaling_policy": "STANDARD",
      "initially_suspended": true
    },
    "adhoc_wh": {
      "name": "ADHOC_WH",
      "comment": "This warehouse will be used for any adhoc purpose",
      "warehouse_size": "X-SMALL",
      "auto_resume": true,
      "auto_suspend": 60,
      "enable_query_acceleration": false,
      "warehouse_type": "STANDARD",
      "min_cluster_count": 1,
      "max_cluster_count": 1,
      "scaling_policy": "STANDARD",
      "initially_suspended": true
    }
  },
  "databases": {
      "bronze": {
      "name": "BRONZE",
      "comment": "Bronze layer - Raw data ingestion from source systems",
      "schemas": [
        {
          "name": "RAW_DATA",
          "comment": "Raw data from all source systems"
        },
        {
          "name": "UTIL",
          "comment": "Utility objects - file formats, stages, storage integrations"
        }
      ],
      "file_formats": {
        "csv": {
          "name": "CSV_FILE_FORMAT",
          "type": "CSV",
          "compression": "AUTO",
          "field_delimiter": ",",
          "record_delimiter": "\\n",
          "skip_header": 1,
          "field_optionally_enclosed_by": "\"",
          "trim_space": true,
          "error_on_column_count_mismatch": false,
          "escape": "NONE",
          "escape_unenclosed_field": "\\",
          "date_format": "AUTO",
          "timestamp_format": "AUTO",
          "null_if": ["NULL", "null", ""],
          "comment": "Standard CSV file format with header"
        },
        "json": {
          "name": "JSON_FILE_FORMAT",
          "type": "JSON",
          "compression": "AUTO",
          "enable_octal": false,
          "allow_duplicate": false,
          "strip_outer_array": false,
          "strip_null_values": false,
          "ignore_utf8_errors": false,
          "comment": "Standard JSON file format"
        }
      },
      "storage_integrations": {
        "s3": {
          "name": "S3_STORAGE_INTEGRATION",
          "type": "EXTERNAL_STAGE",
          "storage_provider": "S3",
          "enabled": true,
          "storage_allowed_locations": ["raw-data/json/", "raw-data/csv/"],
          "storage_blocked_locations": [],
          "comment": "S3 storage integration - allows access to the s3 bucket"
        }
      },
      "stages": {
        "external_s3_csv": {
          "name": "S3_EXTERNAL_STAGE_CSV",
          "schema": "UTIL",
          "url": "s3://the-s3-bucket/raw-data/csv/",
          "storage_integration": "S3_STORAGE_INTEGRATION",
          "file_format": "CSV_FILE_FORMAT",
          "comment": "External stage for S3 CSV data ingestion"
        },
        "external_s3_json": {
          "name": "S3_EXTERNAL_STAGE_JSON",
          "schema": "UTIL",
          "url": "s3://the-s3-bucket/raw-data/json/",
          "storage_integration": "S3_STORAGE_INTEGRATION",
          "file_format": "JSON_FILE_FORMAT",
          "comment": "External stage for S3 JSON data ingestion"
        }
      },
      "tables": {
        "orders_data": {
          "name": "ORDERS_DATA",
          "schema": "RAW_DATA",
          "comment": "Raw orders data from S3",
          "columns": [
            { "name": "ORDER_ID", "type": "STRING" },
            { "name": "CUSTOMER_ID", "type": "STRING" },
            { "name": "ORDER_DATE", "type": "DATE" },
            { "name": "PRODUCT", "type": "STRING" },
            { "name": "QUANTITY", "type": "INTEGER" },
            { "name": "UNIT_PRICE", "type": "NUMBER(10,2)" },
            { "name": "REGION", "type": "STRING" },
            { "name": "SOURCE_FILE", "type": "STRING" },
            { "name": "LOAD_TIMESTAMP", "type": "TIMESTAMP_NTZ", "default": "CURRENT_TIMESTAMP()" }
          ]
        }
      },
      "snowpipes": {
        "orders_pipe": {
          "name": "ORDERS_PIPE",
          "schema": "RAW_DATA",
          "copy_statement": "COPY INTO BRONZE.RAW_DATA.ORDERS_DATA (order_id, customer_id, order_date, product, quantity, unit_price, region, source_file, load_timestamp) FROM (SELECT $1, $2, $3, $4, $5, $6, $7, METADATA$FILENAME, CURRENT_TIMESTAMP() FROM @BRONZE.UTIL.S3_EXTERNAL_STAGE_CSV) FILE_FORMAT = (FORMAT_NAME = 'BRONZE.UTIL.CSV_FILE_FORMAT') PATTERN = '.*orders.*\\.csv'",
          "auto_ingest": true,
          "comment": "Snowpipe for automatic orders CSV data ingestion from S3"
        }
      }
    },
    "silver": {
      "name": "SILVER",
      "comment": "Silver layer - Cleaned, validated, and conformed data",
      "schemas": [
        {
          "name": "CURATED_DATA",
          "comment": "Cleaned and validated data ready for analytics"
        }
      ]
    },
    "gold": {
      "name": "GOLD",
      "comment": "Gold layer - Business-ready aggregated and enriched data",
      "schemas": [
        {
          "name": "ANALYTICS",
          "comment": "Business analytics and aggregated metrics"
        }
      ]
    }
  }
}
